{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SelhbkbDgPeH"
   },
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import tweepy\n",
    "import json\n",
    "\n",
    "import pyrebase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "EgRpDF3oiFEg"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/poobalan/College/Sem 6/mini project/Disaster-Mitigation-Support-System/DatasetFinal2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jnZgfQwCiM_8",
    "outputId": "3e6a2fc6-d6bd-40f0-bca6-b7ae64415390"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hu2qQYeiiSzi",
    "outputId": "b0458f9e-5073-4e73-c787-399d742aa271"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'tweetid', 'username', 'followers_count', 'tweet',\n",
       "       'tweet_created', 'Place', 'Category', 'Unnamed: 8'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vV9DM4_ui24h"
   },
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 8'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "011FMxcGi_8m",
    "outputId": "70dc0c85-38a2-4db5-cded-6bcc8e367e5c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>username</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>Place</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-04-23  13:53</td>\n",
       "      <td>1385486062793883652</td>\n",
       "      <td>Senju Hashirama</td>\n",
       "      <td>0</td>\n",
       "      <td>Volunteers for rescue operations in #Chennaifl...</td>\n",
       "      <td>2021-04-23 06:49:53</td>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-04-23  13:53</td>\n",
       "      <td>1385485726951755777</td>\n",
       "      <td>Senju Hashirama</td>\n",
       "      <td>0</td>\n",
       "      <td>Rescue volunteers for chennai flood are doing ...</td>\n",
       "      <td>2021-04-23 06:48:33</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-04-23  13:54</td>\n",
       "      <td>1385485008995950595</td>\n",
       "      <td>kavinsabapathy</td>\n",
       "      <td>0</td>\n",
       "      <td>our volunteers are in full swing in helping th...</td>\n",
       "      <td>2021-04-23 06:45:41</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>volunteer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-23  13:54</td>\n",
       "      <td>1385484338163175426</td>\n",
       "      <td>kavinsabapathy</td>\n",
       "      <td>0</td>\n",
       "      <td>helping others is the best thing in life. So w...</td>\n",
       "      <td>2021-04-23 06:43:01</td>\n",
       "      <td>Cuddalore</td>\n",
       "      <td>volunteer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-04-23  13:54</td>\n",
       "      <td>1385484705626169346</td>\n",
       "      <td>kavinsabapathy</td>\n",
       "      <td>0</td>\n",
       "      <td>we are happy to announce that we are there to ...</td>\n",
       "      <td>2021-04-23 06:44:29</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>volunteer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                date              tweetid         username  followers_count  \\\n",
       "0  2021-04-23  13:53  1385486062793883652  Senju Hashirama                0   \n",
       "1  2021-04-23  13:53  1385485726951755777  Senju Hashirama                0   \n",
       "2  2021-04-23  13:54  1385485008995950595   kavinsabapathy                0   \n",
       "3  2021-04-23  13:54  1385484338163175426   kavinsabapathy                0   \n",
       "4  2021-04-23  13:54  1385484705626169346   kavinsabapathy                0   \n",
       "\n",
       "                                               tweet        tweet_created  \\\n",
       "0  Volunteers for rescue operations in #Chennaifl...  2021-04-23 06:49:53   \n",
       "1  Rescue volunteers for chennai flood are doing ...  2021-04-23 06:48:33   \n",
       "2  our volunteers are in full swing in helping th...  2021-04-23 06:45:41   \n",
       "3  helping others is the best thing in life. So w...  2021-04-23 06:43:01   \n",
       "4  we are happy to announce that we are there to ...  2021-04-23 06:44:29   \n",
       "\n",
       "        Place   Category  \n",
       "0  Coimbatore    general  \n",
       "1     Chennai    general  \n",
       "2     Chennai  volunteer  \n",
       "3   Cuddalore  volunteer  \n",
       "4     Chennai  volunteer  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "37o4bW5_jHg4"
   },
   "outputs": [],
   "source": [
    "train_x,test_x,train_y,test_y = model_selection.train_test_split(df['tweet'],df['Category'],test_size=0.25,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GytTzBB7kNAe",
    "outputId": "5b016424-8a2e-4789-c685-c4048df0a0d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71     #chennaiflood we are for the people helping or...\n",
       "22     #ChennaiFlood #Resucuevolunteer As of now we  ...\n",
       "204    I am kesav from guindy Got jammed in here with...\n",
       "45     #chennaiflood Days of sufferings The people of...\n",
       "199    Happy to see the people of Chennai helping eac...\n",
       "                             ...                        \n",
       "67     #chennaiflood please donate the things to the ...\n",
       "192    We group of peoples came here to work from Har...\n",
       "117    Ppl are drowning and the government is just wa...\n",
       "47     #rescuevolunteer Those who are willing to resc...\n",
       "172                Can anyone pls help me..#ChennaiFlood\n",
       "Name: tweet, Length: 168, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WSu86NEhkOzN",
    "outputId": "995219ad-9d5f-4034-f2de-a0d8d08722aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71     volunteer\n",
       "22     volunteer\n",
       "204         Help\n",
       "45     volunteer\n",
       "199         Help\n",
       "         ...    \n",
       "67       general\n",
       "192         Help\n",
       "117      general\n",
       "47     volunteer\n",
       "172      general\n",
       "Name: Category, Length: 168, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label encoding the train test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "t1Zp9gCvkVZf"
   },
   "outputs": [],
   "source": [
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "test_y = encoder.fit_transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q45a-RwPki3k",
    "outputId": "e2ab6e88-c165-48b3-b36c-f46c21dfe7ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 2, 0, 2, 1, 1, 2, 2, 1, 2, 0, 2, 2, 0, 1, 2, 2, 2, 2, 1,\n",
       "       0, 2, 1, 1, 2, 0, 1, 2, 1, 0, 2, 1, 0, 0, 0, 1, 2, 1, 2, 2, 0, 2,\n",
       "       0, 2, 0, 1, 0, 0, 2, 2, 2, 2, 0, 0, 2, 1, 2, 1, 2, 0, 0, 0, 0, 0,\n",
       "       1, 2, 1, 2, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 0, 2, 1, 1, 1, 1, 1, 2,\n",
       "       2, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 2, 2, 2, 1, 2, 0, 1, 2, 0,\n",
       "       1, 2, 2, 1, 2, 0, 0, 2, 2, 2, 0, 0, 0, 2, 1, 2, 1, 2, 1, 0, 0, 0,\n",
       "       2, 1, 0, 1, 0, 0, 1, 2, 1, 0, 2, 0, 2, 0, 1, 1, 0, 0, 2, 0, 2, 0,\n",
       "       1, 1, 2, 2, 2, 0, 1, 1, 0, 1, 0, 1, 2, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jR_3vcrCkkre",
    "outputId": "b9454595-9fb1-4746-8c24-5e105415fb15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Help' 'general' 'volunteer']\n"
     ]
    }
   ],
   "source": [
    "print(encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UApy4vv0k2ab",
    "outputId": "e1157944-887d-4c67-dc30-85bb290b947a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Help', 1: 'general', 2: 'volunteer'}\n"
     ]
    }
   ],
   "source": [
    "enc_name_mapping = dict(zip(encoder.transform(encoder.classes_),encoder.classes_))\n",
    "print(enc_name_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "7HeEsXlQlELo"
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(train_x)\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(train_x)\n",
    "xvalid_count =  count_vect.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KZoa9ZGzlguI",
    "outputId": "02aabb12-6bf6-49d4-99e6-634c172f4380"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 42)\t1\n",
      "  (0, 46)\t1\n",
      "  (0, 97)\t1\n",
      "  (0, 159)\t1\n",
      "  (0, 212)\t1\n",
      "  (0, 221)\t1\n",
      "  (0, 283)\t2\n",
      "  (0, 287)\t1\n",
      "  (0, 315)\t1\n",
      "  (0, 320)\t1\n",
      "  (0, 404)\t1\n",
      "  (0, 415)\t1\n",
      "  (0, 449)\t1\n",
      "  (0, 464)\t2\n",
      "  (0, 620)\t2\n",
      "  (0, 641)\t1\n",
      "  (0, 658)\t1\n",
      "  (0, 669)\t1\n",
      "  (0, 690)\t1\n",
      "  (1, 33)\t1\n",
      "  (1, 38)\t1\n",
      "  (1, 46)\t2\n",
      "  (1, 50)\t2\n",
      "  (1, 83)\t1\n",
      "  (1, 86)\t1\n",
      "  :\t:\n",
      "  (165, 632)\t1\n",
      "  (165, 641)\t1\n",
      "  (165, 687)\t1\n",
      "  (166, 46)\t1\n",
      "  (166, 56)\t1\n",
      "  (166, 96)\t1\n",
      "  (166, 97)\t1\n",
      "  (166, 112)\t1\n",
      "  (166, 334)\t1\n",
      "  (166, 464)\t1\n",
      "  (166, 514)\t1\n",
      "  (166, 515)\t1\n",
      "  (166, 620)\t1\n",
      "  (166, 631)\t1\n",
      "  (166, 641)\t1\n",
      "  (166, 669)\t1\n",
      "  (166, 703)\t1\n",
      "  (166, 707)\t1\n",
      "  (166, 710)\t1\n",
      "  (167, 43)\t1\n",
      "  (167, 87)\t1\n",
      "  (167, 97)\t1\n",
      "  (167, 283)\t1\n",
      "  (167, 384)\t1\n",
      "  (167, 475)\t1\n"
     ]
    }
   ],
   "source": [
    "print(xtrain_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "jno7eDmWlktG"
   },
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various Models Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lUXsSgd9l0S8",
    "outputId": "1814cc49-3b03-4b45-850a-ccc87f11799f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Count Vectors:  0.5263157894736842\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xvalid_count)\n",
    "print (\"NB, Count Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "2ir3sxSiDXsP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, N-Gram Vectors:  0.5087719298245614\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(svm.SVC(), xtrain_count, train_y, xvalid_count)\n",
    "print (\"SVM, N-Gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Y2MGbfQAml8S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression, Count Vectors:  0.5263157894736842\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_count, train_y, xvalid_count)\n",
    "print (\"Linear Regression, Count Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "6JWECpcfl7FP"
   },
   "outputs": [],
   "source": [
    "def datapreprocessing(textdata):\n",
    "    #1.conerting the text into lower case\n",
    "    textdata=textdata.lower()\n",
    "    textdata = re.sub(r\"http\\S+\", \"\", textdata)\n",
    "    #2.removing the numbers\n",
    "    result = re.sub(r'\\d+', '', textdata)\n",
    "\n",
    "    entity_prefixes = ['@','#']\n",
    "    for separator in  string.punctuation:\n",
    "        if separator not in entity_prefixes :\n",
    "            result = result.replace(separator,' ')\n",
    "    words = []\n",
    "    for word in result.split():\n",
    "        word = word.strip()\n",
    "        if word:\n",
    "            if word[0] not in entity_prefixes:\n",
    "                words.append(word)\n",
    "    result=(' '.join(words)) \n",
    "\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    \n",
    "    result=emoji_pattern.sub(r'', result)\n",
    "    #3.removing the punctuations\n",
    "  \n",
    "    punc = '!()-[]{};:\\'\\\",<>/?@#$%^&*_~\\'0123456789+.,' \n",
    "    for ele in result:  \n",
    "        if ele in punc:  \n",
    "            result = result.replace(ele, \"\")\n",
    "    \n",
    "    \n",
    "    #4.removing whitespaces\n",
    "    result=result.strip()\n",
    "    \n",
    "    #5.removing stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(result)\n",
    "    result = [i for i in tokens if not i in stop_words]\n",
    "\n",
    "    #6 stemming\n",
    "    word_stemmer=PorterStemmer()\n",
    "    for i in range(len(result)):\n",
    "        result[i]=word_stemmer.stem(result[i])\n",
    "    \n",
    "    print(result)\n",
    "    # 7 lematization\n",
    "    lematizer=WordNetLemmatizer()\n",
    "    for i in range(len(result)):\n",
    "        result[i]=lematizer.lemmatize(result[i])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "_vqVQHdYrsMZ",
    "outputId": "f842cdf5-547c-4dc3-cad0-cb3464fd4ad0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Volunteers for rescue operations in #Chennaifl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rescue volunteers for chennai flood are doing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>our volunteers are in full swing in helping th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>helping others is the best thing in life. So w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>we are happy to announce that we are there to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0  Volunteers for rescue operations in #Chennaifl...\n",
       "1  Rescue volunteers for chennai flood are doing ...\n",
       "2  our volunteers are in full swing in helping th...\n",
       "3  helping others is the best thing in life. So w...\n",
       "4  we are happy to announce that we are there to ..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.DataFrame(df,columns=['tweet'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UMdkRJPXmvMg",
    "outputId": "1203105c-d2c1-4a4c-cfa5-44efe8556cfa",
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['volunt', 'rescu', 'oper', 'need']\n",
      "['rescu', 'volunt', 'chennai', 'flood', 'god', 'workheroeswithoutcap']\n",
      "['volunt', 'full', 'swing', 'help', 'needi', 'pleas', 'kindli', 'inform', 'us', 'ur', 'need', 'help', 'u']\n",
      "['help', 'other', 'best', 'thing', 'life', 'took', 'initi', 'suppli', 'food', 'cloth', 'contact', 'us']\n",
      "['happi', 'announc', 'help', 'u', 'disast', 'situat', 'pl', 'contact', 'us', 'info']\n",
      "['readi', 'volunt', 'suppli', 'food', 'poepl', 'chennai', 'contact', 'us', 'info']\n",
      "['would', 'like', 'extend', 'help', 'hand', 'peopl', 'chennai', 'pl', 'contact', 'us', 'case', 'utmost', 'emerg', 'alway']\n",
      "['readi', 'volunt', 'help', 'peopl', 'chennai', 'overcom', 'flood', 'pl', 'contact', 'us']\n",
      "['calam', 'make', 'thing', 'wors', 'young', 'volunt', 'set', 'thing', 'right', 'need', 'medicin', 'medic', 'aid', 'feel', 'free', 'contact', 'get', 'soon', 'love']\n",
      "['heart', 'weep', 'see', 'peopl', 'suffer', 'huge', 'sinc', 'get', 'know', 'thing', 'will', 'help', 'financi', 'ask', 'help']\n",
      "['regard', 'peopl', 'suffer', 'lot', 'without', 'cloth', 'dharmapuri', 'district', 'collect', 'huge', 'scale', 'cloth', 'rang', 'child', 'elderli', 'peopl', 'get', 'contact']\n",
      "['mani', 'peopl', 'volunt', 'help', 'peopl', 'chennai']\n",
      "['fear', 'volunt', 'club', 'readi', 'help', 'peopl', 'chennai', 'need', 'msg', 'us']\n",
      "['volunt', 'everi', 'organis', 'readi', 'rescu', 'peopl', 'help', 'affect', 'peopl', 'chennai']\n",
      "['volunt', 'join', 'polic', 'rescu', 'member', 'stuck', 'insid', 'hous', 'ecr', 'st', 'cross']\n",
      "['fear', 'rescu', 'team', 'help', 'peopl', 'omr', 'main', 'come', 'situat']\n",
      "['day', 'suffer', 'peopl', 'chennai', 'heart', 'outta', 'help', 'guy', 'contact', 'help']\n",
      "['god', 'tri', 'make', 'thing', 'difficult', 'flood', 'youngster', 'idea', 'wish', 'join', 'hand', 'rescu', 'well', 'chennain']\n",
      "['will', 'rescu', 'peopl', 'chennai', 'come', 'join', 'us']\n",
      "['laligam', 'nss', 'club', 'volunt', 'wish', 'contribut', 'pl', 'contact', 'us', 'rescu', 'process']\n",
      "['group', 'volunt', 'readi', 'help', 'rescu', 'mission', 'heavi', 'flood', 'chennai', 'surround', 'area']\n",
      "['mobil', 'charg', 'station', 'near', 'omr', 'flood', 'affect', 'peopl', 'come', 'use']\n",
      "['came', 'know', 'peopl', 'chennai', 'need', 'thing', 'suffer', 'due', 'flood', 'like', 'help', 'send', 'consum', 'also', 'essenti', 'thing', 'pleas', 'feel', 'free', 'contact', 'us']\n",
      "['budget', 'film', 'wish', 'contribut', 'plz', 'contact', 'us', 'rescu', 'process', 'readi', 'note', 'count', 'suppli', 'food']\n",
      "['come', 'join', 'us', 'let', 'help', 'peopl', 'struggl']\n",
      "['chennai', 'need', 'rescu', 'volunt', 'need', 'save', 'citi', 'anyon', 'interest', 'dm']\n",
      "['peopl', 'chennai', 'suffer', 'lot', 'tri', 'help', 'aspect', 'call', 'us', 'hlp']\n",
      "['volunt', 'rescu', 'oper', 'need']\n",
      "['volunt', 'give', 'food', 'water', 'omr', 'st', 'street', 'volunt', 'readi', 'help', 'street', 'need', 'messag', 'pleas']\n",
      "['rescu', 'volunt', 'chennai', 'flood', 'god', 'workheroeswithoutcap']\n",
      "['larg', 'quantiti', 'food', 'cloth', 'suppli', 'pl', 'let', 'us', 'know', 'ur', 'need', 'emerg']\n",
      "['volunt', 'full', 'swing', 'help', 'needi', 'pl', 'kindli', 'inform', 'us', 'ur', 'need', 'help', 'u']\n",
      "['happi', 'announc', 'help', 'u', 'disast', 'situat', 'pl', 'contact', 'us', 'info']\n",
      "['help', 'other', 'best', 'thing', 'lyf', 'took', 'initi', 'suppli', 'food', 'cloth', 'contact', 'us']\n",
      "['readi', 'volunt', 'suppli', 'food', 'poepl', 'chennai', 'contact', 'us', 'info']\n",
      "['would', 'like', 'extend', 'help', 'hand', 'peopl', 'chennai', 'pl', 'contact', 'us', 'case', 'utmost', 'emerg', 'alway']\n",
      "['readi', 'volunt', 'help', 'peopl', 'chennai', 'overcom', 'flood', 'pl', 'contact', 'us']\n",
      "['calam', 'make', 'thing', 'wors', 'young', 'volunt', 'set', 'thing', 'right', 'need', 'medicin', 'medic', 'aid', 'feel', 'free', 'contact', 'get', 'soon', 'love']\n",
      "['heart', 'weep', 'see', 'peopl', 'suffer', 'huge', 'sinc', 'get', 'know', 'thing', 'will', 'help', 'financi', 'ask', 'help']\n",
      "['regard', 'peopl', 'suffer', 'lot', 'without', 'cloth', 'dharmapuri', 'district', 'collect', 'huge', 'scale', 'cloth', 'rang', 'child', 'elderli', 'peopl', 'get', 'contact']\n",
      "['mani', 'peopl', 'volunt', 'help', 'peopl', 'chennai']\n",
      "['fear', 'volunt', 'club', 'readi', 'help', 'peopl', 'chennai', 'need', 'msg', 'us']\n",
      "['volunt', 'everi', 'organis', 'readi', 'rescu', 'peopl', 'help', 'affect', 'peopl', 'chennai']\n",
      "['volunt', 'join', 'polic', 'rescu', 'member', 'stuck', 'insid', 'hous', 'ecr', 'st', 'cross']\n",
      "['fear', 'rescu', 'team', 'help', 'peopl', 'omr', 'main', 'come', 'situat']\n",
      "['day', 'suffer', 'peopl', 'chennai', 'heart', 'outta', 'help', 'guy', 'contact', 'help']\n",
      "['god', 'tri', 'make', 'thing', 'difficult', 'flood', 'youngster', 'idea', 'wish', 'join', 'hand', 'rescu', 'well', 'chennain']\n",
      "['will', 'rescu', 'peopl', 'chennai', 'come', 'join', 'us']\n",
      "['laligam', 'nss', 'club', 'volunt', 'wish', 'contribut', 'pl', 'contact', 'us', 'rescu', 'process']\n",
      "['group', 'volunt', 'readi', 'help', 'rescu', 'mission', 'heavi', 'flood', 'chennai', 'surround', 'area']\n",
      "['mobil', 'charg', 'station', 'near', 'omr', 'flood', 'affect', 'peopl', 'come', 'use']\n",
      "['came', 'know', 'peopl', 'chennai', 'need', 'thing', 'suffer', 'due', 'flood', 'like', 'help', 'send', 'consum', 'also', 'essenti', 'thing', 'pleas', 'feel', 'free', 'contact', 'us']\n",
      "['budget', 'film', 'wish', 'contribut', 'plz', 'contact', 'us', 'rescu', 'process', 'readi', 'note', 'count', 'suppli', 'food']\n",
      "['team', 'full', 'swing', 'help', 'peopl', 'chennai', 'still', 'power', 'help', 'pl', 'let', 'us', 'know', 'u', 'need', 'help']\n",
      "['food', 'cloth', 'shelter', 'avail', 'us', 'readi', 'give', 'peopl', 'need', 'affect']\n",
      "['team', 'readi', 'hlp', 'peopl', 'need', 'affect', 'pl', 'pl', 'let', 'us', 'know', 'u', 'need', 'help']\n",
      "['food', 'cloth', 'basic', 'need', 'human', 'becom', 'essenti', 'thing', 'chennailit', 'readi', 'offer', 'u']\n",
      "['team', 'youngster', 'march', 'chennai', 'save', 'peopl', 'danger', 'hlp', 'pleas', 'contact', 'us']\n",
      "['hlp', 'peopl', 'chennai', 'offer', 'cloth', 'food', 'team', 'name', 'save', 'peopl']\n",
      "['help', 'fund', 'organis', 'readi', 'help', 'chennai', 'peopl', 'give', 'fund', 'product', 'messag', 'help']\n",
      "['mani', 'peopl', 'help', 'peopl', 'rescu', 'flood', 'area']\n",
      "['provid', 'shelter', 'peopl', 'provid', 'food', 'help', 'pleas', 'messag']\n",
      "['cloth', 'food', 'offer', 'pl', 'contact', 'us', 'readi', 'give', 'anyth', 'u', 'need', 'see', 'peopl', 'need', 'chennai', 'readi', 'serv']\n",
      "['will', 'donat', 'food', 'medicin', 'peopl', 'chennai', 'pleas', 'contact']\n",
      "['team', 'initi', 'help', 'needi', 'affect', 'pl', 'contact', 'hlp', 'u', 'need', 'contact', 'info', 'bio']\n",
      "['help', 'peopl', 'medicin', 'food', 'affect', 'flood', 'want', 'donat', 'pleas', 'messag', 'contact', 'peopl', 'organis']\n",
      "['think', 'god', 'lot', 'sorrow', 'activ', 'cri', 'day', 'got', 'flood', 'state', 'worst']\n",
      "['pleas', 'donat', 'thing', 'peopl', 'affect', 'flood', 'help']\n",
      "['readi', 'donat', 'cloth', 'peopl', 'flood']\n",
      "['peopl', 'readi', 'help', 'peopl', 'food', 'water', 'help', 'distribut', 'pleas', 'contact', 'us', 'repli', 'msg']\n",
      "['dhasavadharam', 'movi', 'larg', 'tsunami', 'shown', 'small', 'one', 'bt', 'small', 'flood', 'make', 'us', 'threaten', 'need', 'improv', 'director']\n",
      "['peopl', 'help', 'organis', 'u', 'need', 'help', 'help', 'peopl', 'flood', 'msg', 'us']\n",
      "['provid', 'food', 'water', 'peopl', 'contact', 'help']\n",
      "['suffici', 'amount', 'medicin', 'need', 'pleas', 'repli']\n",
      "['eye', 'develop', 'countri', 'popul', 'growth', 'decreas', 'chennai', 'mani', 'gone', 'liter']\n",
      "['analys', 'stat', 'news', 'channel', 'live', 'affect', 'live', 'gone', 'need', 'count', 'nation', 'popul', 'accuraci']\n",
      "['see', 'came', 'know', 'one', 'thing', 'natur', 'hit', 'us', 'back', 'even', 'think', 'merciless', 'attack', 'chennai']\n",
      "['need', 'emerg', 'help', 'assist', 'find', 'place', 'stay', 'medic', 'reuiremnt', 'approach']\n",
      "['say', 'god', 'everywher', 'eveyth', 'mean', 'god', 'flood', 'kill', 'us', 'like', 'anyth', 'brutal', 'tq', 'almighti']\n",
      "['fool', 'simpl', 'wast', 'money', 'time', 'unnecessari', 'thing', 'god', 'heartless', 'guy', 'wt', 'brutal']\n",
      "['enough', 'enough', 'enough', 'heart', 'bare', 'cri', 'like', 'anyth', 'wt', 'merciless', 'thing', 'happen', 'chennai']\n",
      "['huff', 'gone', 'heart', 'hurt', 'like', 'see', 'everi', 'face', 'see', 'lot', 'dream', 'gone', 'wast', 'god', 'heart']\n",
      "['ohhh', 'wt', 'sorrow', 'million', 'live', 'gone', 'still', 'go', 'chennai', 'sad', 'god', 'show', 'merci']\n",
      "['need', 'emerg', 'help', 'assist', 'find', 'place', 'stay', 'medic', 'requiremnt', 'approach', 'satisfi', 'ur', 'requir', 'asap']\n",
      "['tough', 'phase', 'cross', 'life', 'learn', 'someth', 'traged', 'event', 'time', 'help', 'us', 'identifi', 'noth', 'perman', 'connect', 'motiv']\n",
      "['need', 'help', 'proper', 'food', 'medic', 'requir', 'feel', 'free', 'contact', 'mr', 'niranjan', 'trust', 'servic', 'mani', 'peopl', 'day']\n",
      "['plenti', 'obstacl', 'difficulti', 'lead', 'us', 'unexpect', 'time', 'natur', 'lesson', 'learn', 'us', 'know', 'good', 'moral', 'recov', 'get', 'path', 'right', 'asap', 'persever']\n",
      "['crew', 'chase', 'help', 'peopl', 'assur', 'shelter', 'motiv', 'feel', 'free', 'contact', 'us', 'situat', 'get', 'connect', 'stay', 'unit']\n",
      "['day', 'pass', 'stage', 'execpt', 'dilemma', 'confus', 'final', 'recoveredand', 'gone', 'let', 'us', 'proceed', 'kind', 'posit', 'cherish']\n",
      "['govern', 'take', 'mani', 'step', 'help', 'peopl', 'save', 'peopl']\n",
      "['near', 'vadapalani', 'bunch', 'tree', 'fallen', 'thu', 'electr', 'connect', 'got', 'disabl', 'pleas', 'take', 'care', 'help', 'us', 'earliest']\n",
      "['provid', 'shelter', 'food', 'mani', 'requir', 'satisfi', 'hard', 'situat', 'still', 'welcom', 'help', 'keep', 'touch', 'whenev', 'u', 'need', 'us']\n",
      "['peopl', 'help', 'eachoth', 'support', 'everyon', 'give', 'medicin', 'share', 'food']\n",
      "['tough', 'tackl', 'wors', 'situat', 'still', 'came', 'huge', 'ton', 'help', 'volunt', 'individu', 'persever', 'need', 'keep', 'motiv', 'stay', 'unit']\n",
      "['near', 'anna', 'nagar', 'electr', 'post', 'fallen', 'wire', 'hang', 'danger', 'run', 'flood', 'water', 'anyon', 'eb', 'board', 'pleas', 'take', 'care', 'issu']\n",
      "['team', 'readi', 'help', 'toughest', 'situat', 'provid', 'basic', 'medic', 'requir', 'food', 'necess', 'pl', 'contact', 'us', 'need']\n",
      "['mani', 'peopl', 'die', 'govern', 'watch', 'without', 'take', 'step']\n",
      "['heart', 'throbe', 'situat', 'never', 'erasen', 'life', 'million', 'peopl', 'live', 'affect', 'brutal', 'still', 'recov', 'bad', 'case', 'stay', 'posit', 'stay', 'unit']\n",
      "['mani', 'young', 'peopl', 'get', 'action', 'help', 'peopl', 'struck', 'chennai', 'flood']\n",
      "['need', 'emerg', 'help', 'assist', 'find', 'place', 'stay', 'medic', 'reuiremnt', 'approachloveal', 'satisfi', 'ur', 'requir', 'asap']\n",
      "['peopl', 'near', 'omr', 'face', 'sever', 'threat', 'hous', 'surround', 'water', 'need', 'immedi', 'rescu', 'sourc']\n",
      "['flood', 'show', 'power', 'natur', 'us', 'natur', 'diaster', 'caus', 'mani', 'lost']\n",
      "['tough', 'phase', 'cross', 'life', 'learn', 'someth', 'traged', 'event', 'time', 'help', 'us', 'identifi', 'noth', 'perman', 'connect', 'motiv']\n",
      "['group', 'member', 'stuck', 'insid', 'hous', 'due', 'flood', 'rain', 'till', 'get', 'rid', 'help']\n",
      "['mani', 'peopl', 'lost', 'home', 'life', 'other', 'flood', 'pray', 'chennai', 'peopl']\n",
      "['stuck', 'heavi', 'rain', 'flood', 'near', 'central', 'need', 'food', 'surviv', 'thing', 'pleas', 'help', 'us']\n",
      "['need', 'help', 'proper', 'food', 'medic', 'requir', 'feel', 'free', 'contact', 'mr', 'madhumithran', 'trust', 'servic', 'mani', 'peopl', 'day']\n",
      "['govern', 'take', 'step', 'till', 'help', 'peopl', 'omr', 'road', 'suffer', 'lot', 'pleas', 'help']\n",
      "['pleas', 'pray', 'peopl', 'struggl', 'flood', 'injur']\n",
      "['mani', 'peopl', 'injur', 'flood', 'lack', 'medic', 'facil', 'medicin', 'nagar']\n",
      "['peopl', 'struggl', 'without', 'food', 'water', 'ecr', 'road', 'govern', 'taken', 'action']\n",
      "['food', 'water', 'mani', 'peopl', 'marina', 'main', 'need', 'help']\n",
      "['member', 'stuck', 'insid', 'hous', 'need', 'help', 'pleas']\n",
      "['peopl', 'need', 'help', 'peopl', 'stuck', 'flood']\n",
      "['plenti', 'obstacl', 'difficulti', 'head', 'us', 'unexpect', 'time', 'natur', 'lesson', 'teach', 'us', 'good', 'moral', 'recov', 'get', 'path', 'right', 'asap', 'uniti']\n",
      "['anyon', 'donat', 'cloth', 'fund', 'peopl', 'chennai', 'around', 'area', 'krishnagiri', 'district', 'pleas', 'contact', 'mr', 'manikandan', 'contact']\n",
      "['crew', 'chase', 'help', 'peopl', 'provid', 'shelter', 'motiv', 'feel', 'free', 'contactu', 'situat', 'get', 'connect', 'fli', 'higher']\n",
      "['ppl', 'drown', 'govern', 'watch', 'think']\n",
      "['send', 'prayer', 'peopl', 'chennai', 'stay', 'strong']\n",
      "['natur', 'disast', 'show', 'realli', 'matter', 'life', 'food', 'shelter', 'health', 'take', 'care', 'ppl', 'chennai']\n",
      "['day', 'pass', 'stage', 'surpass', 'dilemma', 'confus', 'final', 'recov', 'gone', 'let', 'us', 'live', 'kind', 'posit', 'cherish']\n",
      "['help', 'way', 'non', 'profit', 'organis', 'help', 'way', 'dm', 'donat', 'fund', 'help', 'save', 'peopl']\n",
      "['provid', 'shelter', 'food', 'mani', 'requir', 'satisfi', 'hard', 'situat', 'still', 'warm', 'help', 'keep', 'touch', 'whenev', 'u', 'need', 'us']\n",
      "['hard', 'tackl', 'situat', 'still', 'came', 'huge', 'ton', 'help', 'volunt', 'individualenforc', 'need', 'keep', 'motiv', 'stay', 'unit']\n",
      "['team', 'readi', 'help', 'toughest', 'situat', 'provid', 'basic', 'shelter', 'food', 'necess', 'pl', 'contact', 'us', 'need']\n",
      "['life', 'becom', 'difficult', 'even', 'see', 'ground', 'whole', 'citi', 'submerg', 'water', 'need', 'rescu', 'asap']\n",
      "['heart', 'throbe', 'situat', 'never', 'forgetten', 'life', 'million', 'peopl', 'live', 'affect', 'sever', 'still', 'recov', 'wors', 'case', 'stay', 'posit', 'stay', 'unit']\n",
      "['horrif', 'rain', 'chennai', 'heart', 'realli', 'goe', 'everyon', 'volunt', 'helpguy', 'case', 'emerg', 'contact']\n",
      "['potti', 'readi', 'help', 'peopl', 'affect', 'plz', 'believ', 'joint', 'hand', 'us', 'contact', 'us']\n",
      "['budget', 'film', 'readi', 'help', 'peopl', 'affect', 'love', 'help', 'plz', 'contact', 'us', 'plz', 'stay', 'safe']\n",
      "['uniti', 'team', 'team', 'siragug', 'full', 'swing', 'help', 'hilaric', 'fight', 'hlp', 'pl', 'contact', 'us']\n",
      "['great', 'pleasur', 'team', 'save', 'peopl', 'life', 'tie', 'team', 'sirugug', 'start', 'hlp', 'even', 'tq', 'hlp']\n",
      "['team', 'today', 'save', 'child', 'suffer', 'gave', 'place', 'stay', 'food', 'hlp', 'pl', 'contact', 'us']\n",
      "['person', 'know', 'middl', 'class', 'famili', 'also', 'lost', 'father', 'week', 'ago', 'despit', 'poor', 'donat', 'rupe', 'relief', 'fund', 'good', 'happen', 'us', 'let', 'donat']\n",
      "['everyon', 'come', 'forward', 'help', 'peopl', 'im', 'chennai', 'respons', 'bigshot']\n",
      "['oh', 'god', 'cruel', 'thing', 'happen', 'chennai', 'mani', 'peopl', 'suffer', 'outsid', 'must', 'come', 'forward', 'help', 'peopl', 'behalf', 'cit', 'colleg', 'student', 'rais', 'huge', 'fund', 'gon', 'na', 'donat', 'needi', 'pleas', 'support', 'us']\n",
      "['hai', 'team', 'would', 'like', 'help', 'peopl', 'need', 'suffer', 'contact', 'us', 'u', 'need', 'hlp']\n",
      "['got', 'jam', 'week', 'chepauk', 'need', 'help', 'pl']\n",
      "['peopl', 'nehru', 'nagar', 'chepauk', 'need', 'place', 'shelter', 'basic', 'requir', 'pl', 'help', 'us']\n",
      "['heavi', 'flood', 'got', 'stuck', 'chepauk', 'without', 'proper', 'food', 'shelter', 'pl', 'help']\n",
      "['need', 'food', 'drink', 'water', 'chepauk']\n",
      "['kavin', 'food', 'power', 'adayar']\n",
      "['need', 'food', 'drink', 'water', 'keelpakkam']\n",
      "['kesav', 'anna', 'nagar', 'n', 'eed', 'medic', 'help', 'child']\n",
      "['heavi', 'flood', 'got', 'stuck', 'kodambakkam', 'without', 'proper', 'food', 'shelter', 'pl', 'help']\n",
      "['mani', 'chepakk', 'need', 'medic', 'help', 'pregnant', 'wife']\n",
      "['peopl', 'tnagar', 'need', 'place', 'shelter', 'basic', 'requir', 'pl', 'help', 'us']\n",
      "['condit', 'control', 'ecr', 'mani', 'hous', 'fulli', 'drown', 'flood', 'noon', 'go', 'manyar', 'hungri', 'noth', 'eat', 'help', 'need', 'urgent']\n",
      "['seek', 'help', 'year', 'old', 'grandfath', 'realli', 'uncomfort', 'state', 'need', 'medic', 'help', 'pleas', 'help', 'locat', 'ecr']\n",
      "['heavi', 'rain', 'yesterday', 'night', 'still', 'continu', 'mani', 'peopl', 'wash', 'away', 'lot', 'peopl', 'areseek', 'help', 'cheppakkam', 'pleas', 'share', 'max']\n",
      "['got', 'stuck', 'hous', 'food', 'year', 'old', 'kid', 'help', 'need', 'pleas', 'save', 'us', 'pleas', 'vadapalani']\n",
      "['due', 'flood', 'rain', 'lost', 'oru', 'normal', 'life', 'mylapor', 'due', 'stagnent', 'flood', 'water', 'chang', 'get', 'diseas', 'pleas', 'rescu', 'us']\n",
      "['exist', 'heavi', 'flood', 'triplican', 'could', 'see', 'mani', 'peopl', 'got', 'trap', 'roof', 'build', 'need', 'help']\n",
      "['emerg', 'pleas', 'help', 'us', 'strcuk', 'flood', 'eat', 'past', 'day']\n",
      "['mani', 'peopl', 'live', 'near', 'slum', 'lost', 'hous', 'everyth', 'place', 'stay', 'pleas', 'help']\n",
      "['hello', 'everyon', 'struck', 'koratur', 'friend', 'pleas', 'provid', 'us', 'food', 'help', 'us']\n",
      "['rescu', 'year', 'old', 'son', 'nagar', 'school', 'find', 'flood', 'pl', 'help', 'u']\n",
      "['group', 'peopl', 'came', 'gujarat', 'work', 'got', 'struck', 'flood', 'pleas', 'help', 'us']\n",
      "['came', 'chennai', 'day', 'ago', 'still', 'stuck', 'egmor', 'bu', 'stand']\n",
      "['heavi', 'rain', 'flood', 'sinc', 'yesterday', 'morn', 'triplican', 'hous', 'surround', 'flood']\n",
      "['niranjan', 'adayar', 'got', 'stuck', 'year', 'old', 'child', 'past', 'day', 'need', 'emerg', 'help', 'rescu', 'immedi']\n",
      "['need', 'boat', 'rescu', 'old', 'peopl', 'fold', 'hand']\n",
      "['need', 'food', 'water', 'hous', 'fulli', 'flood', 'ecr', 'st', 'cross']\n",
      "['happi', 'see', 'peopl', 'chennai', 'help', 'share', 'ration', 'time', 'distress', 'human', 'still', 'exist', 'fold', 'hand']\n",
      "['medic', 'attent', 'requir', 'peopl', 'north', 'madra', 'pl', 'tend', 'need']\n",
      "['lega', 'walk', 'ryt', 'poor', 'food', 'today', 'properti', 'gone', 'along', 'flood', 'pl', 'hlp', 'guy']\n",
      "['short', 'suppli', 'food', 'peopl', 'parri', 'corner', 'volunt', 'nearbi', 'area', 'help', 'need']\n",
      "['call', 'immedi', 'action', 'central', 'govern', 'take', 'step', 'ensur', 'well', 'citizen', 'tamil', 'nadu']\n",
      "['chennai', 'flood', 'caus', 'casualti', 'stay', 'togeth', 'time', 'distress']\n",
      "['heavi', 'rain', 'flood', 'sinc', 'yesterday', 'morn', 'triplican', 'hous', 'surround', 'flood', 'also', 'need', 'help', 'rescu']\n",
      "['chennai', 'flood', 'disastr', 'event', 'tn', 'ever', 'wit', 'period']\n",
      "['peopl', 'nehru', 'nagar', 'adayar', 'need', 'place', 'shelter', 'basic', 'requir', 'pl', 'help', 'us']\n",
      "['anyon', 'pl', 'help']\n",
      "['hope', 'come', 'back', 'stronger']\n",
      "['heavi', 'flood', 'got', 'stuck', 'egmor', 'without', 'proper', 'food', 'shelter', 'pl', 'help']\n",
      "['got', 'jam', 'week', 'need', 'help', 'pl']\n",
      "['parthiv', 'adayar', 'n', 'eed', 'medic', 'help', 'pregnant', 'wife']\n",
      "['heartbroken', 'hear', 'thing', 'happen']\n",
      "['seen', 'mani', 'volunt', 'help', 'peopl', 'prove', 'us', 'stand', 'togeth', 'anytim', 'whenev', 'need', 'need', 'proud', 'tamilan']\n",
      "['lot', 'peopl', 'life', 'live', 'devast', 'human', 'see', 'one', 'worst', 'situat', 'face', 'hope', 'come', 'back', 'stronger']\n",
      "['peopl', 'gandhi', 'nagar', 'pallavaram', 'home', 'live', 'complet', 'nourish', 'need', 'place', 'shelter', 'andbas', 'requir', 'pl', 'help', 'us']\n",
      "['kesav', 'guindi', 'need', 'medic', 'help', 'pregnant', 'wife', 'seek', 'medic', 'requir', 'week', 'pl', 'help', 'us']\n",
      "['group', 'peopl', 'came', 'work', 'punjab', 'becoz', 'heavi', 'flood', 'got', 'stuck', 'adayar', 'without', 'properfood', 'shelter', 'pl', 'help', 'us']\n",
      "['seen', 'mani', 'volunt', 'help', 'peopl', 'prove', 'us', 'stand', 'togeth', 'anytim', 'whenev', 'need', 'proud', 'tamilan']\n",
      "['lot', 'peopl', 'life', 'live', 'devast', 'human', 'see', 'one', 'worst', 'situat', 'face', 'hope', 'come', 'back', 'stronger']\n",
      "['moment', 'silenc', 'peopl', 'die']\n",
      "['peopl', 'nehru', 'nagar', 'mamallapuram', 'home', 'live', 'complet', 'nourish', 'need', 'place', 'shelter', 'basic', 'requir', 'pl', 'help', 'us']\n",
      "['chennai', 'flood', 'exampl', 'natur', 'retribut', 'ignor', 'mankind']\n",
      "['mani', 'adayar', 'need', 'medic', 'help', 'pregnant', 'wife', 'seek', 'medic', 'requir', 'week', 'pl', 'help', 'us']\n",
      "['need', 'food', 'drink', 'water', 'kodambakkam']\n",
      "['lost', 'littl', 'dog', 'heavi', 'rain', 'flood', 'near', 'adayar', 'anyon', 'see', 'brown', 'colour', 'countri', 'dog', 'pleas', 'contact', 'number']\n",
      "['stay', 'strong', 'peopl', 'chennai', 'whloe', 'tn', 'stand']\n",
      "['group', 'peopl', 'came', 'work', 'haryana', 'becoz', 'heavi', 'flood', 'got', 'stuck', 'egmor', 'without', 'proper', 'food', 'shelter', 'pl', 'help', 'us']\n",
      "['food', 'power', 'tnagar']\n",
      "['group', 'peopl', 'suffer', 'flood', 'water', 'near', 'chepauk', 'need', 'food', 'surviv', 'stuff', 'pleas', 'help']\n",
      "['peopl', 'stuck', 'insid', 'hous', 'omr', 'main', 'road', 'need', 'peopl', 'immedi']\n",
      "['need', 'medic', 'thing', 'first', 'aid', 'thing', 'peopl', 'anna', 'nagar', 'pleas', 'help']\n",
      "['anna', 'nagar', 'sever', 'danger', 'food', 'power', 'due', 'heavi', 'rain', 'flood', 'pleas']\n",
      "['emerg', 'group', 'peopl', 'stuck', 'rain', 'flood', 'near', 'guindi', 'pleas', 'help', 'faster']\n",
      "['happi', 'see', 'peopl', 'chennai', 'help', 'share', 'ration', 'time', 'distress', 'humanitystil', 'exist']\n",
      "['need', 'help', 'search', 'lost', 'year', 'old', 'son', 'tnagar', 'day', 'couldnt', 'find', 'contact', 'polic', 'time', 'done', 'pl', 'rescu']\n",
      "['kesav', 'sembarambakkam', 'new', 'coloni', 'sever', 'peopl', 'suffer', 'abund', 'refresh', 'food', 'past', 'day', 'stay', 'open', 'terrac', 'need', 'help', 'immedi']\n",
      "['need', 'help', 'grandma', 'year', 'old', 'diabet', 'patient', 'adayar', 'seek', 'forc', 'medic', 'help', 'day', 'pl', 'rescu']\n",
      "['heartfelt', 'condol', 'peopl', 'lost', 'live', 'chennai', 'flood']\n",
      "['kesav', 'guindi', 'got', 'jam', 'year', 'old', 'child', 'past', 'day', 'need', 'emerg', 'help']\n",
      "['need', 'enough', 'food', 'shelter', 'near', 'egmor', 'sinc', 'forc', 'help', 'us', 'need', 'emerg', 'rescu']\n",
      "['home', 'place', 'sleep', 'place', 'water', 'peopl', 'need', 'help']\n",
      "['great', 'effort', 'taken', 'armi', 'polic', 'help', 'strand', 'peopl', 'chennai', 'kudo']\n",
      "['central', 'govt', 'said', 'support', 'us', 'relief', 'fund', 'peopl', 'watch']\n",
      "['need', 'help', 'guy', 'need', 'food', 'refresh', 'rescu', 'need', 'immedi', 'help', 'peopl']\n",
      "['anna', 'nagar', 'sever', 'danger', 'food', 'power', 'due', 'heavi', 'rain', 'flood', 'pleas', 'help', 'us', 'earlier']\n",
      "['came', 'adayar', 'friend', 'place', 'stay', 'food', 'got', 'jam', 'week', 'need', 'help', 'pl']\n",
      "['emerg', 'group', 'peopl', 'stuck', 'rain', 'flood', 'near', 'guindi', 'pleas', 'help', 'faster']\n",
      "['need', 'rescu', 'lost', 'year', 'old', 'daughter', 'egmor', 'day', 'couldnt', 'search', 'contact', 'thepolic', 'time', 'pl', 'help', 'find']\n",
      "['mani', 'usman', 'road', 'tnagar', 'lot', 'peopl', 'suffer', 'abund', 'food', 'refresh', 'past', 'day', 'stay', 'open', 'terrac', 'need', 'rescu', 'immedi']\n",
      "['need', 'medic', 'emerg', 'grandpa', 'year', 'old', 'diabet', 'patient', 'egmor', 'seek', 'rescu', 'week', 'medic', 'help']\n",
      "['manikandan', 'adayar', 'got', 'stuck', 'year', 'old', 'child', 'past', 'day', 'need', 'emerg', 'help', 'rescu', 'immedi']\n",
      "['chennai', 'flood', 'exampl', 'oncom', 'global', 'warm']\n",
      "['need', 'enough', 'food', 'shelter', 'near', 'guindi', 'sinc', 'one', 'head', 'help', 'us', 'sinc', 'hr', 'pl', 'need', 'asap']\n",
      "['food', 'power', 'place', 'stay', 'shelter', 'wash', 'away', 'flood', 'slum', 'peopl', 'desper', 'need', 'help']\n",
      "['heartbroken', 'hear', 'thing', 'happen', 'stay', 'strong', 'peopl', 'chennai', 'whole', 'tn', 'stand']\n",
      "['devast', 'news', 'heart', 'goe', 'ppl', 'chennai']\n",
      "['need', 'medicin', 'near', 'enor', 'help', 'us']\n",
      "['need', 'boat', 'rescu', 'old', 'peopl', 'near', 'omr']\n",
      "['what', 'use', 'chancey', 'illa', 'song', 'one', 'come', 'unaffect', 'area', 'help', 'peopl', 'affect', 'smh']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-291f5be5b8d0>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tweet'][i] = datapreprocessing(df['tweet'][i])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>username</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>Place</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-04-23  13:53</td>\n",
       "      <td>1385486062793883652</td>\n",
       "      <td>Senju Hashirama</td>\n",
       "      <td>0</td>\n",
       "      <td>[volunt, rescu, oper, need]</td>\n",
       "      <td>2021-04-23 06:49:53</td>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-04-23  13:53</td>\n",
       "      <td>1385485726951755777</td>\n",
       "      <td>Senju Hashirama</td>\n",
       "      <td>0</td>\n",
       "      <td>[rescu, volunt, chennai, flood, god, workheroe...</td>\n",
       "      <td>2021-04-23 06:48:33</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-04-23  13:54</td>\n",
       "      <td>1385485008995950595</td>\n",
       "      <td>kavinsabapathy</td>\n",
       "      <td>0</td>\n",
       "      <td>[volunt, full, swing, help, needi, plea, kindl...</td>\n",
       "      <td>2021-04-23 06:45:41</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>volunteer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-23  13:54</td>\n",
       "      <td>1385484338163175426</td>\n",
       "      <td>kavinsabapathy</td>\n",
       "      <td>0</td>\n",
       "      <td>[help, other, best, thing, life, took, initi, ...</td>\n",
       "      <td>2021-04-23 06:43:01</td>\n",
       "      <td>Cuddalore</td>\n",
       "      <td>volunteer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-04-23  13:54</td>\n",
       "      <td>1385484705626169346</td>\n",
       "      <td>kavinsabapathy</td>\n",
       "      <td>0</td>\n",
       "      <td>[happi, announc, help, u, disast, situat, pl, ...</td>\n",
       "      <td>2021-04-23 06:44:29</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>volunteer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                date              tweetid         username  followers_count  \\\n",
       "0  2021-04-23  13:53  1385486062793883652  Senju Hashirama                0   \n",
       "1  2021-04-23  13:53  1385485726951755777  Senju Hashirama                0   \n",
       "2  2021-04-23  13:54  1385485008995950595   kavinsabapathy                0   \n",
       "3  2021-04-23  13:54  1385484338163175426   kavinsabapathy                0   \n",
       "4  2021-04-23  13:54  1385484705626169346   kavinsabapathy                0   \n",
       "\n",
       "                                               tweet        tweet_created  \\\n",
       "0                        [volunt, rescu, oper, need]  2021-04-23 06:49:53   \n",
       "1  [rescu, volunt, chennai, flood, god, workheroe...  2021-04-23 06:48:33   \n",
       "2  [volunt, full, swing, help, needi, plea, kindl...  2021-04-23 06:45:41   \n",
       "3  [help, other, best, thing, life, took, initi, ...  2021-04-23 06:43:01   \n",
       "4  [happi, announc, help, u, disast, situat, pl, ...  2021-04-23 06:44:29   \n",
       "\n",
       "        Place   Category  \n",
       "0  Coimbatore    general  \n",
       "1     Chennai    general  \n",
       "2     Chennai  volunteer  \n",
       "3   Cuddalore  volunteer  \n",
       "4     Chennai  volunteer  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(df['tweet'].count()):\n",
    "    df['tweet'][i] = datapreprocessing(df['tweet'][i])\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "GPjNJqumoHpY"
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(train_x)\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(train_x)\n",
    "xvalid_count =  count_vect.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uj_5bYuiwlYa",
    "outputId": "31d45ffb-f168-4c5b-a498-e4f2480100ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Count Vectors:  0.5263157894736842\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xvalid_count)\n",
    "print (\"NB, Count Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nJOdXjkM-9fy",
    "outputId": "74fcd5c6-a4dd-4c42-92ad-d598fa0b9fc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, N-Gram Vectors:  0.5087719298245614\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(svm.SVC(), xtrain_count, train_y, xvalid_count)\n",
    "print (\"SVM, N-Gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Huq8kNx2x2p-",
    "outputId": "f28cb96d-7315-402e-e4cf-83a65cb31fe9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression, Count Vectors:  0.5263157894736842\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_count, train_y, xvalid_count)\n",
    "print (\"Linear Regression, Count Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking User input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Dti_vzQoxGSP"
   },
   "outputs": [],
   "source": [
    "def input_predict(classifier, feature_vector_train, label, feature_vector_valid):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iWXaO5J1wrri",
    "outputId": "60afb16d-9de3-4dc9-ad91-04917fd7af72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 38)\t1\n",
      "  (0, 46)\t1\n",
      "  (0, 219)\t1\n",
      "  (0, 283)\t1\n",
      "  (0, 312)\t1\n",
      "  (0, 415)\t1\n",
      "  (0, 464)\t1\n",
      "  (0, 472)\t1\n",
      "  (0, 566)\t1\n",
      "  (0, 597)\t1\n",
      "  (0, 669)\t1\n"
     ]
    }
   ],
   "source": [
    "new_input = ['I need some 10 foods packets and 20 waterbottles people are suffering please help us ']\n",
    "#new_input = datapreprocessing(new_input)\n",
    "new_input_count = count_vect.transform(new_input)\n",
    "print(new_input_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0n4XL9kExeVa",
    "outputId": "3432cdc0-9c94-4b4c-e288-e8ad2665885c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "result = input_predict(naive_bayes.MultinomialNB(),xtrain_count,train_y,new_input_count)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nFHv-ngWAV-A",
    "outputId": "4f3d7aa2-1648-4e4d-e46e-28f5c4105f64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "result = input_predict(linear_model.LogisticRegression(),xtrain_count,train_y,new_input_count)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zBuicob8Cs-f",
    "outputId": "dc604931-e5dd-4db0-c135-7e74f27a8859"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "result = input_predict(svm.SVC(),xtrain_count,train_y,new_input_count)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing the tweepy object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSUMER_KEY = \"tNsobFwICnhvijyXWNC7selyC\"\n",
    "CONSUMER_SECRET = \"nOBFm8D9qUS5A7JlqjLU7yOTXFLIkwLvYYae2fGB7JF0NKHKkf\"\n",
    "ACCESS_KEY = \"1355541876741300227-dIdVt9dimhdibKGGdTidCoxTz8sJSR\"\n",
    "ACCESS_SECRET = \"soyCrMxlRHcFASlyzbrT5yCNsFJ20YzjQM5zoRn8jY1eY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_KEY, ACCESS_SECRET)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing the firebase object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"apiKey\": \"AIzaSyAysywWbD4O4UPpCQrci50kaLHVQbrJm7Y\",\n",
    "    \"authDomain\": \"dmss-308701.firebaseapp.com\",\n",
    "    \"databaseURL\": \"https://dmss-308701-default-rtdb.firebaseio.com\",\n",
    "    \"projectId\": \"dmss-308701\",\n",
    "    \"storageBucket\": \"dmss-308701.appspot.com\",\n",
    "    \"messagingSenderId\": \"245597012331\",\n",
    "    \"appId\": \"1:245597012331:web:0da20d1dc511e17a074c2e\",\n",
    "    \"measurementId\": \"G-HJ72TBGN7T\"\n",
    "}\n",
    "\n",
    "firebase = pyrebase.initialize_app(config)\n",
    "\n",
    "db=firebase.database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting tweets live from twitter and classifying it and updating the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already Marked on the Map\n",
      "Already replied to Tweet with the details\n"
     ]
    }
   ],
   "source": [
    "for tweet in tweepy.Cursor(api.search, q=\"#ChennaiFloods\", count=1, lang=\"en\", since=\"2021-04-25\").items():  \n",
    "\n",
    "    if tweet.id_str not in list(db.child(\"Tweetids\").child().get().val()):\n",
    "        new_input = [tweet.text]\n",
    "#         new_input = datapreprocessing(new_input)\n",
    "        new_input_count = count_vect.transform(new_input)\n",
    "        predict = input_predict(linear_model.LogisticRegression(),xtrain_count,train_y,new_input_count)\n",
    "        \n",
    "        if predict[0] == 0:\n",
    "            textdata=\"Thanks for reaching for help visit here https://disaster-mitigation-support-system.netlify.app/ and contact the volunteer nearby you Be Safe\"\n",
    "        if predict[0]== 1:\n",
    "            textdata=\"Thanks for sharing the general information.Be Safe\"\n",
    "        if predict[0] == 2:\n",
    "            textdata=\"Thanks for reaching to help others visit here https://disaster-mitigation-support-system.netlify.app/ and register as our volunter and help the people in need.Be Safe\"\n",
    "        \n",
    "        api.update_status(textdata, in_reply_to_status_id=tweet.id,auto_populate_reply_metadata=True)\n",
    "        db.child(\"Tweetids\").child(tweet.id).set(tweet.id)\n",
    "        \n",
    "        from geopy.geocoders import Nominatim\n",
    "        \n",
    "        geolocator = Nominatim(user_agent=\"DMSS\")\n",
    "        loc=tweet.user.location\n",
    "        location = geolocator.geocode(loc)\n",
    "        data={\"location\":loc,\"latitude\":location.latitude,\"longitude\":location.longitude}\n",
    "        \n",
    "        if loc not in list(db.child(\"Locations\").child().get().val()):\n",
    "            db.child(\"Locations\").child(loc).set(data)\n",
    "        else:\n",
    "            print(\"Already Marked on the Map\")\n",
    "    else:\n",
    "        print(\"Already replied to Tweet with the details\")\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ML.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
